{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Advanced RAG: Contextual Cypher Retrieval\n",
    "\n",
    "You can improve the vector retriever by using a custom Cypher query to provide richer, more contextual answers.\n",
    "\n",
    "You will need to:\n",
    "\n",
    "- Create a Cypher `retrieval_query` that will be used with the retriever\n",
    "- Use the `VectorCypherRetriever` class to create the retriever\n",
    "- Create a `GraphRAG` pipeline that uses the retriever\n",
    "\n",
    "---\n",
    "\n",
    "Import the required Python modules, load the environment variables, create the connection to the graph, the LLM, and the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../new-workshops/solutions')\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "\n",
    "from config import Neo4jConfig, get_llm, get_embedder\n",
    "\n",
    "neo4j_config = Neo4jConfig()\n",
    "driver = GraphDatabase.driver(neo4j_config.uri, auth=(neo4j_config.username, neo4j_config.password))\n",
    "\n",
    "# --- Initialize LLM and Embedder from Microsoft Foundry ---\n",
    "llm = get_llm()\n",
    "embedder = get_embedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Create a `VectorCypherRetriever` that uses a Cypher query to return additional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using COLLECT subquery to limit asset managers per company.\n",
    "# This ensures top_k controls the final result count, not just vector search nodes.\n",
    "# Without this, graph traversal can expand 5 nodes into many more rows (one per manager).\n",
    "asset_manager_query = \"\"\"\n",
    "MATCH (node)-[:FROM_DOCUMENT]-(doc:Document)-[:FILED]-(company:Company)\n",
    "WITH node, company, COLLECT {\n",
    "  MATCH (company)-[:OWNS]-(manager:AssetManager)\n",
    "  RETURN manager.managerName\n",
    "  LIMIT 5\n",
    "} AS managers\n",
    "RETURN company.name AS company, managers AS AssetManagersWithSharesInCompany, node.text AS context\n",
    "\"\"\"\n",
    "\n",
    "vector_cypher_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name='chunkEmbeddings',\n",
    "    embedder=embedder,\n",
    "    retrieval_query=asset_manager_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**How it works:**  \n",
    "\n",
    "- **Custom Cypher Query:**  \n",
    "  The `asset_manager_query` matches text chunks (`node`) to their source documents, associated companies, and the asset managers.\n",
    "\n",
    "  It returns:\n",
    "  \n",
    "  1. The company name\n",
    "  2. A list of asset managers associated with the company\n",
    "  3. The context text from the chunk\n",
    "\n",
    "- **VectorCypherRetriever:**  \n",
    "  - Performs semantic search using the `chunkEmbeddings` vector index.\n",
    "  - Applies the Cypher `retrieval_query` to retrieve relevant context and associated asset managers.\n",
    "\n",
    "---\n",
    "\n",
    "Use the `GraphRAG` class to run a pipeline that uses the `vector_cypher_retriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize RAG and Perform Search ---\n",
    "query = \"Who are the asset managers most affected by banking regulations?\"\n",
    "\n",
    "rag = GraphRAG(llm=llm, retriever=vector_cypher_retriever)\n",
    "response = rag.search(query, retriever_config={\"top_k\": 5}, return_context=True)\n",
    "\n",
    "print(f\"Number of results returned: {len(response.retriever_result.items)}\\n\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "The `GraphRAG` pipeline will use the `vector_cypher_retriever` to gain the additional context from the graph. \n",
    "\n",
    "The `vector_cypher_retriever` enables highly specific, context-rich answers which leverage the graph relationships and semantic search.\n",
    "\n",
    "This pattern is ideal when your question is about relationships or context that can be surfaced from relevant passages, and when you want to return both the context and the structured entities connected to it.  \n",
    "\n",
    "If you ask the same question but don't return any additional context from the graph, the answer is less relevant, more generic, and doesn't include any specific asset managers.\n",
    "\n",
    "---\n",
    "\n",
    "You can provide additional parameters to the `search` method to return and customize the number of results returned by the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize RAG, search with options and return context ---\n",
    "rag = GraphRAG(llm=llm, retriever=vector_cypher_retriever)\n",
    "response = rag.search(\n",
    "    query,\n",
    "    retriever_config={\"top_k\": 5},\n",
    "    return_context=True\n",
    "    )\n",
    "\n",
    "print(f\"Number of results returned: {len(response.retriever_result.items)}\\n\")\n",
    "print(response.answer)\n",
    "print(\"\\nContext:\", *response.retriever_result.items, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "The context is returned and printed to the screen, you can use this information to determine the relevance of the data being sent to the LLM.\n",
    "\n",
    "Modify the `\"top_k\"` value from `5` to `10` and then to `20` and review the context returned.\n",
    "\n",
    "As you increase the number of values returned the results become less and less relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Finding Shared Risks Among Companies\n",
    "\n",
    "You can combine semantic search with graph traversal to uncover relationships - specifically, risks that connect major tech companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VectorCypherRetriever Example: Finding Shared Risks Among Companies\n",
    "vector_company_risk_query = \"\"\"\n",
    "WITH node\n",
    "MATCH (node)-[:FROM_DOCUMENT]-(doc:Document)-[:FILED]-(c1:Company)\n",
    "MATCH (c1)-[:FACES_RISK]->(risk:RiskFactor)<-[:FACES_RISK]-(c2:Company)\n",
    "WHERE c1 <> c2\n",
    "RETURN\n",
    "  c1.name AS source_company,\n",
    "  collect(DISTINCT c2.name) AS related_companies,\n",
    "  collect(DISTINCT risk.name) AS shared_risks\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "vector_cypher_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name=\"chunkEmbeddings\",\n",
    "    embedder=embedder,\n",
    "    retrieval_query=vector_company_risk_query\n",
    ")\n",
    "\n",
    "query = \"What risks connect major tech companies?\"\n",
    "rag = GraphRAG(llm=llm, retriever=vector_cypher_retriever)\n",
    "response = rag.search(\n",
    "    query,\n",
    "    retriever_config={\"top_k\": 5},\n",
    "    return_context=True\n",
    "    )\n",
    "\n",
    "print(f\"Number of results returned: {len(response.retriever_result.items)}\\n\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the context used in this query\n",
    "print(\"Context:\", *response.retriever_result.items, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "**How this works:**\n",
    "\n",
    "- **Semantic Search:**  \n",
    "  The vector retriever finds the top-k text chunks most relevant to your query (\"What risks connect major tech companies?\").\n",
    "\n",
    "- **Graph Traversal:**  \n",
    "  For each retrieved chunk (`node`):\n",
    "  - Follows the `:FROM_DOCUMENT` and `:FILED` relationships to a company (`c1`).\n",
    "  - Finds all risk factors (`risk`) that `c1` faces.\n",
    "  - Finds other companies (`c2`) that also face the same risk factor.\n",
    "  - Ensures that `c1` and `c2` are different companies.\n",
    "\n",
    "- **Returns:**  \n",
    "  - `source_company`: The company from the retrieved chunk.\n",
    "  - `related_companies`: Companies sharing at least one risk with the source company.\n",
    "  - `shared_risks`: The names of the risk factors connecting these companies.\n",
    "\n",
    "- **Why this is powerful:**  \n",
    "  - Leverages the chunk as the semantic anchor, but then uses graph logic to discover structured, multi-entity relationships.\n",
    "  - Surfaces both the context (from the chunk) and the broader network of shared risksâ€”something that pure semantic or pure graph search alone would struggle to do as effectively.\n",
    "\n",
    "This approach is ideal for exploratory questions about relationships in your graph, where you want to start from relevant context but end up with structured, comparative insights.\n",
    "\n",
    "---\n",
    "\n",
    "Experiment with these examples, modify the `query` to review how the context returned by the retriever changes the response.\n",
    "\n",
    "[View the complete code](../new-workshops/solutions/02_02_vector_cypher_retriever.py)\n",
    "\n",
    "[Move on to the Text2Cypher Retriever Notebook](02_03_text2cypher_retriever.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-workshops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
