{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Embeddings and Vector Search\n",
    "\n",
    "This notebook demonstrates how to generate embeddings for text chunks and perform vector similarity search using Neo4j.\n",
    "\n",
    "**Prerequisites:** Complete [01_01 Data Loading](01_01_data_loading.ipynb) first.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what embeddings are and why they matter for RAG\n",
    "- Use `FixedSizeSplitter` to automatically chunk text\n",
    "- Generate embeddings using Azure OpenAI\n",
    "- Create a vector index in Neo4j\n",
    "- Perform similarity search to find relevant chunks\n",
    "\n",
    "---\n",
    "\n",
    "## What are Embeddings?\n",
    "\n",
    "Embeddings are numerical representations (vectors) of text that capture semantic meaning. Similar texts have similar embeddings, enabling **semantic search** - finding content by meaning rather than exact keywords.\n",
    "\n",
    "```\n",
    "\"Apple makes iPhones\" → [0.12, -0.45, 0.78, ...] (1536 dimensions)\n",
    "\"The company produces smartphones\" → [0.11, -0.44, 0.77, ...] (similar vector!)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../solutions')\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "\n",
    "from config import Neo4jConfig, get_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-data-header",
   "metadata": {},
   "source": [
    "## Sample Data\n",
    "\n",
    "We use the same sample SEC 10-K text as the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sample-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text length: 1079 characters\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_TEXT = \"\"\"\n",
    "Apple Inc. (\"Apple\" or the \"Company\") designs, manufactures and markets smartphones, \n",
    "personal computers, tablets, wearables and accessories, and sells a variety of related \n",
    "services. The Company's fiscal year is the 52- or 53-week period that ends on the last \n",
    "Saturday of September.\n",
    "\n",
    "Products\n",
    "\n",
    "iPhone is the Company's line of smartphones based on its iOS operating system. The iPhone \n",
    "product line includes iPhone 14 Pro, iPhone 14, iPhone 13 and iPhone SE. Mac is the Company's \n",
    "line of personal computers based on its macOS operating system. iPad is the Company's line \n",
    "of multi-purpose tablets based on its iPadOS operating system.\n",
    "\n",
    "Services\n",
    "\n",
    "Advertising includes third-party licensing arrangements and the Company's own advertising \n",
    "platforms. AppleCare offers a portfolio of fee-based service and support products. Cloud \n",
    "Services store and keep customers' content up-to-date across all devices. Digital Content \n",
    "operates various platforms for discovering, purchasing, streaming and downloading digital \n",
    "content and apps. Payment Services include Apple Card and Apple Pay.\n",
    "\"\"\".strip()\n",
    "\n",
    "DOCUMENT_PATH = \"form10k-sample/apple-2023-10k.pdf\"\n",
    "print(f\"Sample text length: {len(SAMPLE_TEXT)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connect-header",
   "metadata": {},
   "source": [
    "## Connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "connect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j successfully!\n"
     ]
    }
   ],
   "source": [
    "neo4j_config = Neo4jConfig()\n",
    "driver = GraphDatabase.driver(\n",
    "    neo4j_config.uri,\n",
    "    auth=(neo4j_config.username, neo4j_config.password)\n",
    ")\n",
    "driver.verify_connectivity()\n",
    "print(\"Connected to Neo4j successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-header",
   "metadata": {},
   "source": [
    "## Clear Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clear-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 2 nodes\n"
     ]
    }
   ],
   "source": [
    "def clear_graph(driver):\n",
    "    \"\"\"Remove all Document and Chunk nodes.\"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n) WHERE n:Document OR n:Chunk\n",
    "            DETACH DELETE n\n",
    "            RETURN count(n) as deleted\n",
    "        \"\"\")\n",
    "        count = result.single()[\"deleted\"]\n",
    "        print(f\"Deleted {count} nodes\")\n",
    "\n",
    "clear_graph(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "splitter-header",
   "metadata": {},
   "source": [
    "## Split Text with FixedSizeSplitter\n",
    "\n",
    "The `FixedSizeSplitter` from neo4j-graphrag automatically splits text into chunks of a specified size with overlap.\n",
    "\n",
    "- **chunk_size**: Maximum characters per chunk\n",
    "- **chunk_overlap**: Characters to overlap between chunks (preserves context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "split-text",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 3 chunks:\n",
      "\n",
      "Chunk 0: 400 chars\n",
      "  Apple Inc. (\"Apple\" or the \"Company\") designs, manufactures and markets smartphones, \n",
      "personal computers, tablets, wearables and accessories, and sells a variety of related \n",
      "services. The Company's fiscal year is the 52- or 53-week period that ends on the last \n",
      "Saturday of September.\n",
      "\n",
      "Products\n",
      "\n",
      "iPhone is the Company's line of smartphones based on its iOS operating system. The iPhone \n",
      "product line \n",
      "\n",
      "Chunk 1: 400 chars\n",
      "  ts iOS operating system. The iPhone \n",
      "product line includes iPhone 14 Pro, iPhone 14, iPhone 13 and iPhone SE. Mac is the Company's \n",
      "line of personal computers based on its macOS operating system. iPad is the Company's line \n",
      "of multi-purpose tablets based on its iPadOS operating system.\n",
      "\n",
      "Services\n",
      "\n",
      "Advertising includes third-party licensing arrangements and the Company's own advertising \n",
      "platforms. \n",
      "\n",
      "Chunk 2: 379 chars\n",
      "  nts and the Company's own advertising \n",
      "platforms. AppleCare offers a portfolio of fee-based service and support products. Cloud \n",
      "Services store and keep customers' content up-to-date across all devices. Digital Content \n",
      "operates various platforms for discovering, purchasing, streaming and downloading digital \n",
      "content and apps. Payment Services include Apple Card and Apple Pay.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create splitter with small chunk size for demonstration\n",
    "splitter = FixedSizeSplitter(chunk_size=400, chunk_overlap=50)\n",
    "\n",
    "# Split the text (async method - Jupyter supports top-level await)\n",
    "chunks = await splitter.run(text=SAMPLE_TEXT)\n",
    "\n",
    "print(f\"Split into {len(chunks.chunks)} chunks:\\n\")\n",
    "for i, chunk in enumerate(chunks.chunks):\n",
    "    print(f\"Chunk {i}: {len(chunk.text)} chars\")\n",
    "    print(f\"  {chunk.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedder-header",
   "metadata": {},
   "source": "## Initialize Embedder\n\nCreate an embedder using Microsoft Foundry. This uses the `text-embedding-ada-002` model which produces 1536-dimensional vectors."
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "embedder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedder initialized: text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "embedder = get_embedder()\n",
    "print(f\"Embedder initialized: {embedder.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-header",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "Generate an embedding vector for each chunk. This calls the Azure OpenAI embedding API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "generate-embeddings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: Generated 1536-dimensional embedding\n",
      "Chunk 1: Generated 1536-dimensional embedding\n",
      "Chunk 2: Generated 1536-dimensional embedding\n",
      "\n",
      "First 5 values of chunk 0's embedding: [0.0033809475135058165, -0.003419476794078946, -0.008592037484049797, -0.023002002388238907, 0.000592789554502815]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each chunk\n",
    "chunk_embeddings = []\n",
    "for i, chunk in enumerate(chunks.chunks):\n",
    "    embedding = embedder.embed_query(chunk.text)\n",
    "    chunk_embeddings.append({\n",
    "        \"text\": chunk.text,\n",
    "        \"index\": i,\n",
    "        \"embedding\": embedding\n",
    "    })\n",
    "    print(f\"Chunk {i}: Generated {len(embedding)}-dimensional embedding\")\n",
    "\n",
    "print(f\"\\nFirst 5 values of chunk 0's embedding: {chunk_embeddings[0]['embedding'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "store-header",
   "metadata": {},
   "source": [
    "## Store in Neo4j with Embeddings\n",
    "\n",
    "Create Document and Chunk nodes, storing the embedding vector on each Chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "store-chunks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Document: form10k-sample/apple-2023-10k.pdf\n",
      "Created 3 Chunk nodes with embeddings\n",
      "Created NEXT_CHUNK relationships\n"
     ]
    }
   ],
   "source": [
    "def store_chunks_with_embeddings(driver, doc_path: str, chunk_data: list[dict]):\n",
    "    \"\"\"Store Document and Chunk nodes with embeddings.\"\"\"\n",
    "    with driver.session() as session:\n",
    "        # Create Document\n",
    "        session.run(\"\"\"\n",
    "            CREATE (d:Document {path: $path})\n",
    "        \"\"\", path=doc_path)\n",
    "        print(f\"Created Document: {doc_path}\")\n",
    "        \n",
    "        # Create Chunks with embeddings\n",
    "        for chunk in chunk_data:\n",
    "            session.run(\"\"\"\n",
    "                MATCH (d:Document {path: $path})\n",
    "                CREATE (c:Chunk {\n",
    "                    text: $text,\n",
    "                    index: $index,\n",
    "                    embedding: $embedding\n",
    "                })\n",
    "                CREATE (c)-[:FROM_DOCUMENT]->(d)\n",
    "            \"\"\", path=doc_path, text=chunk[\"text\"], \n",
    "               index=chunk[\"index\"], embedding=chunk[\"embedding\"])\n",
    "        print(f\"Created {len(chunk_data)} Chunk nodes with embeddings\")\n",
    "        \n",
    "        # Create NEXT_CHUNK relationships\n",
    "        session.run(\"\"\"\n",
    "            MATCH (d:Document {path: $path})<-[:FROM_DOCUMENT]-(c:Chunk)\n",
    "            WITH c ORDER BY c.index\n",
    "            WITH collect(c) as chunks\n",
    "            UNWIND range(0, size(chunks)-2) as i\n",
    "            WITH chunks[i] as c1, chunks[i+1] as c2\n",
    "            CREATE (c1)-[:NEXT_CHUNK]->(c2)\n",
    "        \"\"\", path=doc_path)\n",
    "        print(\"Created NEXT_CHUNK relationships\")\n",
    "\n",
    "store_chunks_with_embeddings(driver, DOCUMENT_PATH, chunk_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "index-header",
   "metadata": {},
   "source": [
    "## Create Vector Index\n",
    "\n",
    "Create a vector index in Neo4j for efficient similarity search. The index uses cosine similarity to compare embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "create-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped existing index: chunkEmbeddings\n",
      "Created vector index: chunkEmbeddings\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"chunkEmbeddings\"\n",
    "\n",
    "# Drop existing index if it exists\n",
    "try:\n",
    "    with driver.session() as session:\n",
    "        session.run(f\"DROP INDEX {INDEX_NAME} IF EXISTS\")\n",
    "        print(f\"Dropped existing index: {INDEX_NAME}\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create new vector index\n",
    "create_vector_index(\n",
    "    driver=driver,\n",
    "    name=INDEX_NAME,\n",
    "    label=\"Chunk\",\n",
    "    embedding_property=\"embedding\",\n",
    "    dimensions=1536,\n",
    "    similarity_fn=\"cosine\"\n",
    ")\n",
    "print(f\"Created vector index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-header",
   "metadata": {},
   "source": [
    "## Vector Similarity Search\n",
    "\n",
    "Now we can search for chunks that are semantically similar to a query. The search:\n",
    "1. Converts the query to an embedding\n",
    "2. Finds chunks with similar embedding vectors\n",
    "3. Returns results ranked by similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"What products does Apple make?\"\n",
      "\n",
      "============================================================\n",
      "\n",
      "[1] Score: 0.9340 (Chunk 0)\n",
      "    Apple Inc. (\"Apple\" or the \"Company\") designs, manufactures and markets smartphones, \n",
      "personal computers, tablets, wearables and accessories, and sells a variety of related \n",
      "services. The Company's fiscal year is the 52- or 53-week period that ends on the last \n",
      "Saturday of September.\n",
      "\n",
      "Products\n",
      "\n",
      "iPhone is the Company's line of smartphones based on its iOS operating system. The iPhone \n",
      "product line \n",
      "\n",
      "[2] Score: 0.9182 (Chunk 1)\n",
      "    ts iOS operating system. The iPhone \n",
      "product line includes iPhone 14 Pro, iPhone 14, iPhone 13 and iPhone SE. Mac is the Company's \n",
      "line of personal computers based on its macOS operating system. iPad is the Company's line \n",
      "of multi-purpose tablets based on its iPadOS operating system.\n",
      "\n",
      "Services\n",
      "\n",
      "Advertising includes third-party licensing arrangements and the Company's own advertising \n",
      "platforms. \n",
      "\n",
      "[3] Score: 0.9140 (Chunk 2)\n",
      "    nts and the Company's own advertising \n",
      "platforms. AppleCare offers a portfolio of fee-based service and support products. Cloud \n",
      "Services store and keep customers' content up-to-date across all devices. Digital Content \n",
      "operates various platforms for discovering, purchasing, streaming and downloading digital \n",
      "content and apps. Payment Services include Apple Card and Apple Pay.\n"
     ]
    }
   ],
   "source": [
    "def vector_search(driver, embedder, query: str, top_k: int = 3):\n",
    "    \"\"\"Search for chunks similar to the query.\"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = embedder.embed_query(query)\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"\"\"\n",
    "            CALL db.index.vector.queryNodes($index_name, $top_k, $embedding)\n",
    "            YIELD node, score\n",
    "            RETURN node.text as text, node.index as idx, score\n",
    "            ORDER BY score DESC\n",
    "        \"\"\", index_name=INDEX_NAME, top_k=top_k, embedding=query_embedding)\n",
    "        \n",
    "        return list(result)\n",
    "\n",
    "# Test search\n",
    "query = \"What products does Apple make?\"\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = vector_search(driver, embedder, query)\n",
    "for i, record in enumerate(results):\n",
    "    print(f\"\\n[{i+1}] Score: {record['score']:.4f} (Chunk {record['idx']})\")\n",
    "    print(f\"    {record['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## Compare Different Queries\n",
    "\n",
    "Try different queries to see how semantic search finds relevant content even with different wording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: \"Tell me about iPhone and Mac computers\"\n",
      "--------------------------------------------------\n",
      "Best match (score: 0.9302):\n",
      "  ts iOS operating system. The iPhone \n",
      "product line includes iPhone 14 Pro, iPhone 14, iPhone 13 and iPhone SE. Mac is the Company's \n",
      "line of personal computers based on its macOS operating system. iPad is the Company's line \n",
      "of multi-purpose tablets based on its iPadOS operating system.\n",
      "\n",
      "Services\n",
      "\n",
      "Advertising includes third-party licensing arrangements and the Company's own advertising \n",
      "platforms. \n",
      "\n",
      "Query: \"What services does the company offer?\"\n",
      "--------------------------------------------------\n",
      "Best match (score: 0.9181):\n",
      "  nts and the Company's own advertising \n",
      "platforms. AppleCare offers a portfolio of fee-based service and support products. Cloud \n",
      "Services store and keep customers' content up-to-date across all devices. Digital Content \n",
      "operates various platforms for discovering, purchasing, streaming and downloading digital \n",
      "content and apps. Payment Services include Apple Card and Apple Pay.\n",
      "\n",
      "Query: \"When does the fiscal year end?\"\n",
      "--------------------------------------------------\n",
      "Best match (score: 0.8939):\n",
      "  Apple Inc. (\"Apple\" or the \"Company\") designs, manufactures and markets smartphones, \n",
      "personal computers, tablets, wearables and accessories, and sells a variety of related \n",
      "services. The Company's fiscal year is the 52- or 53-week period that ends on the last \n",
      "Saturday of September.\n",
      "\n",
      "Products\n",
      "\n",
      "iPhone is the Company's line of smartphones based on its iOS operating system. The iPhone \n",
      "product line \n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Tell me about iPhone and Mac computers\",\n",
    "    \"What services does the company offer?\",\n",
    "    \"When does the fiscal year end?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 50)\n",
    "    results = vector_search(driver, embedder, query, top_k=1)\n",
    "    if results:\n",
    "        record = results[0]\n",
    "        print(f\"Best match (score: {record['score']:.4f}):\")\n",
    "        print(f\"  {record['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Embeddings** - Numerical vectors that capture semantic meaning\n",
    "2. **FixedSizeSplitter** - Automatic text chunking with overlap\n",
    "3. **Vector storage** - Storing embeddings as node properties\n",
    "4. **Vector index** - Enabling efficient similarity search\n",
    "5. **Semantic search** - Finding content by meaning, not just keywords\n",
    "\n",
    "The chunks now have embeddings that enable semantic retrieval. In the next notebook, you'll learn to extract **entities** from these chunks to build a richer knowledge graph.\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** [Entity Extraction Basics](01_03_entity_extraction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "driver.close()\n",
    "print(\"Connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-workshops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}