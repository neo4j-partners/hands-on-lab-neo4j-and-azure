{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GraphRAG Retrievers\n",
    "\n",
    "This notebook demonstrates retrieval strategies for GraphRAG applications, progressing from simple vector search to graph-enhanced retrieval with custom Cypher queries.\n",
    "\n",
    "**Prerequisites:** Complete [01 Data and Embeddings](01_data_and_embeddings.ipynb) first.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Set up a VectorRetriever using Neo4j's vector index\n",
    "- Perform semantic similarity searches on your knowledge graph\n",
    "- Use GraphRAG to combine vector search with LLM-generated answers\n",
    "- Create custom Cypher queries with VectorCypherRetriever for richer context\n",
    "- Compare standard vs. graph-enhanced retrieval results\n",
    "\n",
    "---\n",
    "\n",
    "## Retrieval Strategies Overview\n",
    "\n",
    "We'll explore two retrieval approaches:\n",
    "\n",
    "1. **VectorRetriever** - Simple semantic search using embeddings\n",
    "   - Finds chunks by meaning similarity\n",
    "   - Returns raw text for LLM context\n",
    "\n",
    "2. **VectorCypherRetriever** - Graph-enhanced semantic search\n",
    "   - Uses vector search as entry point\n",
    "   - Traverses graph relationships for richer context\n",
    "   - Returns structured data alongside text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required modules and initialize connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import VectorRetriever, VectorCypherRetriever\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "\n",
    "from data_utils import Neo4jConnection, get_llm, get_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Connect to Neo4j\n",
    "\n",
    "Create and verify the connection to your Neo4j graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j = Neo4jConnection().verify()\n",
    "driver = neo4j.driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Initialize LLM and Embedder\n",
    "\n",
    "Set up the Large Language Model (LLM) and embedding model for GraphRAG workflows.\n",
    "\n",
    "- **LLM**: Uses Microsoft Foundry's model via the `OpenAILLM` interface\n",
    "- **Embedder**: Uses Microsoft Foundry's embedding API via `OpenAIEmbeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_llm()\n",
    "embedder = get_embedder()\n",
    "\n",
    "print(f\"LLM initialized: {llm.model_name}\")\n",
    "print(f\"Embedder initialized: {embedder.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Vector Retriever\n",
    "\n",
    "The VectorRetriever performs semantic search over your Neo4j knowledge graph. Instead of keyword matching, it finds the most contextually similar passages to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Initialize Vector Retriever\n",
    "\n",
    "Set up the vector-based retriever for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = VectorRetriever(\n",
    "    driver=driver,\n",
    "    index_name='chunkEmbeddings',\n",
    "    embedder=embedder,\n",
    "    return_properties=['text']\n",
    ")\n",
    "\n",
    "print(\"VectorRetriever initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The **VectorRetriever** class:\n",
    "- Connects to Neo4j using the provided `driver`\n",
    "- Uses the `chunkEmbeddings` vector index for efficient semantic retrieval\n",
    "- The `embedder` generates embeddings for the query\n",
    "- Returns the `text` property from matching chunks\n",
    "\n",
    "> **Tip:** You can modify the `return_properties` list to include additional properties from the retrieved nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Simple Vector Search\n",
    "\n",
    "Test the vector search by retrieving the top 5 most relevant text chunks for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the risks that Apple faces?\"\n",
    "result = vector_retriever.search(query_text=query, top_k=5)\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(f\"Number of results returned: {len(result.items)}\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for item in result.items:\n",
    "    print(f\"\\nScore: {item.metadata['score']:.4f}\")\n",
    "    print(f\"Content: {item.content[0:150]}...\")\n",
    "    print(f\"ID: {item.metadata['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "1. The query is converted to an embedding vector\n",
    "2. `vector_retriever.search()` finds the top 5 matches based on vector similarity\n",
    "3. Results show the similarity score, content snippet, and chunk ID\n",
    "\n",
    "> **Tip:** Inspecting returned results helps verify relevance and adjust your chunking or embedding strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## GraphRAG Pipeline\n",
    "\n",
    "The `GraphRAG` class combines a Large Language Model (LLM) with a vector-based retriever to answer questions using both semantic search and generative reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the risks that Apple faces?\"\n",
    "\n",
    "rag = GraphRAG(\n",
    "    llm=llm,\n",
    "    retriever=vector_retriever\n",
    ")\n",
    "\n",
    "response = rag.search(query, retriever_config={\"top_k\": 5}, return_context=True)\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(f\"Number of chunks used: {len(response.retriever_result.items)}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAnswer:\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "1. The retriever (`vector_retriever`) finds the most relevant text chunks\n",
    "2. The LLM uses the retrieved context to generate a natural language answer\n",
    "3. The `return_context=True` option lets you see what context was used\n",
    "\n",
    "The GraphRAG pipeline provides context-aware, accurate answers grounded in your knowledge graph data.\n",
    "\n",
    "---\n",
    "\n",
    "**Try different queries:**\n",
    "- What products does Microsoft reference?\n",
    "- What warnings have Nvidia given?\n",
    "- What companies mention AI in their filings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Vector Cypher Retriever\n",
    "\n",
    "The VectorCypherRetriever enhances vector search with custom Cypher queries, enabling you to traverse graph relationships and return richer, more contextual answers.\n",
    "\n",
    "This approach is ideal when:\n",
    "- Questions involve relationships between entities\n",
    "- You want structured data alongside text context\n",
    "- Graph traversal can surface insights that text alone cannot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Example 1: Asset Manager Enrichment\n",
    "\n",
    "Create a VectorCypherRetriever that returns companies and their asset managers alongside the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Cypher query to enrich results with asset manager information\n",
    "# Using COLLECT subquery to limit asset managers per company\n",
    "# This ensures top_k controls the final result count, not just vector search nodes\n",
    "\n",
    "asset_manager_query = \"\"\"\n",
    "MATCH (node)-[:FROM_DOCUMENT]-(doc:Document)-[:FILED]-(company:Company)\n",
    "WITH node, company, COLLECT {\n",
    "  MATCH (company)-[:OWNS]-(manager:AssetManager)\n",
    "  RETURN manager.managerName\n",
    "  LIMIT 5\n",
    "} AS managers\n",
    "RETURN company.name AS company, managers AS AssetManagersWithSharesInCompany, node.text AS context\n",
    "\"\"\"\n",
    "\n",
    "vector_cypher_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name='chunkEmbeddings',\n",
    "    embedder=embedder,\n",
    "    retrieval_query=asset_manager_query\n",
    ")\n",
    "\n",
    "print(\"VectorCypherRetriever initialized with asset manager query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "**How this query works:**\n",
    "\n",
    "- Matches text chunks (`node`) to their source documents and associated companies\n",
    "- For each company, collects up to 5 asset managers\n",
    "- Returns: company name, list of asset managers, and context text\n",
    "\n",
    "The `COLLECT` subquery limits results per row, ensuring `top_k` controls the final count rather than being multiplied by graph traversal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who are the asset managers most affected by banking regulations?\"\n",
    "\n",
    "rag = GraphRAG(llm=llm, retriever=vector_cypher_retriever)\n",
    "response = rag.search(query, retriever_config={\"top_k\": 5}, return_context=True)\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(f\"Number of results: {len(response.retriever_result.items)}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAnswer:\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the enriched context used by the LLM\n",
    "print(\"Context used:\")\n",
    "print(\"=\" * 70)\n",
    "for item in response.retriever_result.items:\n",
    "    print(f\"\\n{item.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Notice how the context includes structured data (company names, asset manager lists) alongside the text. This enables more specific, accurate answers than text alone.\n",
    "\n",
    "> **Tip:** Modify `top_k` to see how changing the result count affects relevance. As you increase values, results become less relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Example 2: Discovering Shared Risks Among Companies\n",
    "\n",
    "Combine semantic search with graph traversal to uncover relationships - specifically, risk factors that connect major tech companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Cypher to find companies sharing the same risk factors\n",
    "# Uses slice notation [0..10] on collect() to limit array sizes per row\n",
    "\n",
    "shared_risks_query = \"\"\"\n",
    "WITH node\n",
    "MATCH (node)-[:FROM_DOCUMENT]-(doc:Document)-[:FILED]-(c1:Company)\n",
    "MATCH (c1)-[:FACES_RISK]->(risk:RiskFactor)<-[:FACES_RISK]-(c2:Company)\n",
    "WHERE c1 <> c2\n",
    "WITH c1, c2, risk\n",
    "RETURN\n",
    "  c1.name AS source_company,\n",
    "  collect(DISTINCT c2.name)[0..10] AS related_companies,\n",
    "  collect(DISTINCT risk.name)[0..10] AS shared_risks\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "risk_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name=\"chunkEmbeddings\",\n",
    "    embedder=embedder,\n",
    "    retrieval_query=shared_risks_query\n",
    ")\n",
    "\n",
    "print(\"VectorCypherRetriever initialized with shared risks query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What risks connect major tech companies?\"\n",
    "\n",
    "rag = GraphRAG(llm=llm, retriever=risk_retriever)\n",
    "response = rag.search(query, retriever_config={\"top_k\": 5}, return_context=True)\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(f\"Number of results: {len(response.retriever_result.items)}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAnswer:\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the graph-derived context\n",
    "print(\"Context (shared risks between companies):\")\n",
    "print(\"=\" * 70)\n",
    "for item in response.retriever_result.items:\n",
    "    print(f\"\\n{item.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "**How this works:**\n",
    "\n",
    "1. **Semantic Search:** Finds top-k text chunks relevant to the query\n",
    "2. **Graph Traversal:** For each chunk:\n",
    "   - Follows `FROM_DOCUMENT` and `FILED` relationships to find the company\n",
    "   - Finds risk factors (`FACES_RISK`) that company faces\n",
    "   - Finds other companies facing the same risks\n",
    "3. **Returns:** Source company, related companies, and shared risk factors\n",
    "\n",
    "**Why this is powerful:**\n",
    "- Uses the chunk as a semantic anchor, then graph logic discovers structured relationships\n",
    "- Surfaces network-level insights that pure semantic or pure graph search alone cannot\n",
    "- Ideal for exploratory questions about connections in your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Comparing Retrieval Strategies\n",
    "\n",
    "Let's compare the same query using both retrievers to see the difference in context and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_query = \"What risks do technology companies face?\"\n",
    "\n",
    "print(f\"Query: \\\"{comparison_query}\\\"\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Basic Vector Retriever\n",
    "print(\"\\n[1] VECTOR RETRIEVER (text only)\")\n",
    "print(\"-\" * 40)\n",
    "rag_basic = GraphRAG(llm=llm, retriever=vector_retriever)\n",
    "response_basic = rag_basic.search(comparison_query, retriever_config={\"top_k\": 3})\n",
    "print(response_basic.answer)\n",
    "\n",
    "# Graph-Enhanced Retriever\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\n[2] VECTOR CYPHER RETRIEVER (graph-enhanced)\")\n",
    "print(\"-\" * 40)\n",
    "rag_enhanced = GraphRAG(llm=llm, retriever=risk_retriever)\n",
    "response_enhanced = rag_enhanced.search(comparison_query, retriever_config={\"top_k\": 3})\n",
    "print(response_enhanced.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "**Key Differences:**\n",
    "\n",
    "| Aspect | VectorRetriever | VectorCypherRetriever |\n",
    "|--------|-----------------|----------------------|\n",
    "| Context | Raw text chunks | Text + structured graph data |\n",
    "| Relationships | Implicit in text | Explicit via Cypher traversal |\n",
    "| Answer specificity | General | Specific entities and connections |\n",
    "| Best for | General Q&A | Relationship-focused questions |\n",
    "\n",
    "**When to use each:**\n",
    "- **VectorRetriever**: Simple semantic search, general questions\n",
    "- **VectorCypherRetriever**: Questions about relationships, comparisons, or when you need structured data alongside text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned two retrieval strategies for GraphRAG:\n",
    "\n",
    "**Part 1 - Vector Retriever:**\n",
    "1. Simple semantic search using vector embeddings\n",
    "2. GraphRAG pipeline combining retrieval with LLM generation\n",
    "3. Diagnostic inspection of search results\n",
    "\n",
    "**Part 2 - Vector Cypher Retriever:**\n",
    "4. Custom Cypher queries for graph traversal\n",
    "5. Enriching context with structured entity data\n",
    "6. Discovering relationships (shared risks, asset managers)\n",
    "\n",
    "**Part 3 - Comparison:**\n",
    "7. Understanding when to use each approach\n",
    "8. Trade-offs between simplicity and richness\n",
    "\n",
    "The graph-enhanced approach leverages Neo4j's relationship traversal to provide more specific, contextual answers - the core value proposition of GraphRAG.\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to [Lab 6 - Foundry Agents](../Lab_6_Foundry_Agents) to build intelligent agents that use your knowledge graph as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "neo4j.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
